---
title: "Project"
author: "Ruotong Li"
date: "2/16/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(psych) 
library(tidyverse)
library(gridExtra)
library(corrplot)
```

```{r cars}
data <- read.csv("heart.csv",
         header = TRUE, stringsAsFactors = TRUE)
data$FastingBS <- as.factor(data$FastingBS)
summary(data)
data$Cholesterol[data$Cholesterol==0] <- NA
data$RestingBP[data$RestingBP==0] <- NA
sum(is.na(data$RestingBP))
sum(is.na(data$Cholesterol))
```


```{r pressure, echo=FALSE}
par(mfrow=c(1,3))
hist(data$RestingBP,main='Resting Blood Pressure',breaks=5)
hist(data$Cholesterol,main='Cholesterol',breaks=5)
hist(data$MaxHR,main='Maximum Heart Rate',breaks=5)
```
```{r}
Yheart <- filter(data,HeartDisease==1)
Nheart <- filter(data,HeartDisease==0)
par(mfrow=c(2,1))
boxplot(Yheart$RestingBP,main='Resting BP for Heart Disease',horizontal=TRUE,ylim = c(75, 205),outline=TRUE)
boxplot(Nheart$RestingBP,main='Resting BP for No Heart Disease',horizontal=TRUE,ylim = c(75, 205),outline=TRUE)

par(mfrow=c(2,1))
boxplot(Yheart$Cholesterol,main='Cholesterol for Heart Disease',horizontal=TRUE,ylim = c(90, 605),outline=TRUE)
boxplot(Nheart$Cholesterol,main='Cholesterol for No Heart Disease',horizontal=TRUE,ylim = c(90, 605),outline=TRUE)

par(mfrow=c(2,1))
boxplot(Yheart$MaxHR,main='Maximum Heart Rate for Heart Disease',horizontal=TRUE,ylim = c(55, 200),outline=TRUE)
boxplot(Nheart$MaxHR,main='Maximum Heart Rate for No Heart Disease',horizontal=TRUE,ylim = c(55, 200),outline=TRUE)
```


```{r}
heartdisease <- as.factor(data$HeartDisease)
plot1 = ggplot(data,aes(x=ChestPainType,fill=heartdisease))+geom_bar(position = 'fill')+facet_wrap(~ST_Slope)+
  labs(title='Bar plots distinguish Chest Pain type and ST slope with heart disease')
plot1
plot2 = ggplot(data,aes(x=RestingECG,fill=heartdisease))+geom_bar(position = 'fill')+facet_wrap(~ExerciseAngina)+
  labs(title='Bar plots distinguish Resting ECG and Exercise Angina with heart disease')
plot2
plot3 = ggplot(data,aes(x=FastingBS,fill=heartdisease))+geom_bar(position = 'fill')+
  labs(title='Bar plots distinguish Fasting Blood Sugar with heart disease')
plot3
```

```{r}
M = mean(data$RestingBP,na.rm=TRUE)
data$RestingBP[is.na(data$RestingBP)] = M
```

```{r}
library('mice')
imputedE=mice(data,method = 'pmm', maxit = 20)
```

```{r}
summary(data$Cholesterol)
```

```{r}
imputedE$imp$Cholesterol
```
```{r}
mean(imputedE$imp$Cholesterol$`1`)
mean(imputedE$imp$Cholesterol$`2`)
mean(imputedE$imp$Cholesterol$`3`)
mean(imputedE$imp$Cholesterol$`4`)
mean(imputedE$imp$Cholesterol$`5`)

df = complete(imputedE,1)
summary(df)
```

```{r}
df[c(1, 4, 5, 8, 10)] <- scale(df[c(1, 4, 5, 8, 10)])
summary(df)
head(df,5)
```
```{r}
idx = sample(nrow(df), nrow(df)*0.7)
train = as.data.frame((df[idx,]))
test = as.data.frame(df[-idx,])
nrow(train)
nrow(test)
```

#Subset selection based on exhaustive search in logistic regression
#3 chest pain types,
```{r}
library(ISLR)
library(leaps)
regfit.full = regsubsets(HeartDisease~., train,nvmax = 15)
reg.summary = summary(regfit.full)
names(reg.summary)
reg.summary
```

#RSQ and RSS
```{r}
plot(reg.summary$rsq, xlab = 'Number of variables', ylab = 'R Square', type = 'l')
plot(reg.summary$rss, xlab = 'Number of variables', ylab = 'RSS', type = 'l')
```

#Adjusted R sqaure
```{r}
opt.r2 = which.max(reg.summary$adjr2)
plot(reg.summary$adjr2, xlab = 'Number of variables', ylab = 'Adjusted R square', type = 'l')
points(opt.r2, reg.summary$adjr2[opt.r2], col = 'red', cex = 1, pch = 20)
```

#Cp
```{r}
opt.cp = which.min(reg.summary$cp)
plot(reg.summary$cp, xlab = 'Number of variables', ylab = 'Cp', type = 'l')
points(opt.cp, reg.summary$cp[opt.cp], col = 'red', cex = 1, pch = 20)
```

#BIC
```{r}
opt.bic = which.min(reg.summary$bic)
plot(reg.summary$bic, xlab = 'Number of variables', ylab = 'BIC', type = 'l')
points(opt.bic, reg.summary$bic[opt.bic], col = 'red', cex = 1, pch = 20)
```
#Validation set
```{r}
regfit.best = regsubsets(HeartDisease~., train, nvmax = 15)
test.mat = model.matrix(HeartDisease~., test)
val.errors = rep(NA,15)
for(i in 1:15){
  coefi = coef(regfit.best, id=i)
  pred = test.mat[,names(coefi)]%*% coefi
  adjustedr2[i] = 1-(sum((test$HeartDisease - pred)^2)/(nrow(test)-i-1))/(sum((test$HeartDisease - mean(test$HeartDisease))^2)/(nrow(test)-1))
}
plot(adjustedr2)
```
#So when choosing 9 and 11 variables, validation error is minimized. With consideration of RSS, all 11 variables
#are chose to fit a regression model.
```{r}
coef(regfit.best,10)
```

#Model model testing and evaluation function,evaluate based on accuracy,confusion matrix, and ROC curve.
```{r}
library('caret')
library( 'ROCR' )
#for a classification problem, the dependent variable should be factor
train$HeartDisease = as.factor(train$HeartDisease)
test$HeartDisease = as.factor(test$HeartDisease)
# evaluate function
evaluate = function(model,testset,label,threshold=0.5){
  #confusion matrix,use threshold to filter prediction values
  predicted = predict(model, testset,type="response")
  predicted_thresh =  ifelse((predicted)>threshold,"1","0") %>% as.factor()
  print(confusionMatrix(data=predicted_thresh, reference = label))
  #Roc curve
  pred = prediction(predicted, label)
  perf = performance(pred, "acc")
  roc = performance(pred,"tpr","fpr")
  plot(roc, colorize = T, lwd = 2)
}
```

# train logistic regression model with picked variables (11) here, test and evaluate the model
```{r}
logit <- glm(HeartDisease ~.-RestingBP - Cholesterol - RestingECG, data = train, family = "binomial")
evaluate(logit,test,test$HeartDisease)
```

```{r}
logit
```
```{r}
logit_ori <- glm(HeartDisease ~., data = train, family = "binomial")
evaluate(logit_ori,test,test$HeartDisease)
```

#Use lasso for feature selection comparing to best subset in logistic regression 
```{r}
library(glmnet)
# Dumy code categorical predictor variables
x <- model.matrix(HeartDisease~., train)
y = as.factor(train$HeartDisease)
cv.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial")
plot(cv.lasso)
# Fit the final model on the training data
model_lasso <- glmnet(x, y, alpha = 1,family = 'binomial')
# Make predictions on the test data
x.test <- model.matrix(HeartDisease ~., test)
label = as.factor(test$HeartDisease)

# Make predictions
probabilities <- model_lasso %>% predict(x.test, type = "response") %>% as.vector()
predicted.classes <- ifelse(probabilities > 0.5, "1", "0")
# Model accuracy
observed.classes <- label
mean(predicted.classes == observed.classes)
```



#train and evaluate a KNN modelï¼Œcombining with cross-validation process
#numerica label is needed
```{r}
df1 = lapply(df, function(x) as.numeric(as.character(x)))
x = createFolds(df1$Age, k = 5, list = TRUE, returnTrain = FALSE)
test01 = df1[x$Fold1, ]
train01 = df1[-x$Fold1, ]

test02 = df1[x$Fold2, ]
train02 = df1[-x$Fold2, ]

test03 = df1[x$Fold3, ]
train03 = df1[-x$Fold3, ]

test04 = df1[x$Fold4, ]
train04 = df1[-x$Fold4, ]

test05 = df1[x$Fold5, ]
train05 = df1[-x$Fold5, ]

length(x$Fold1)

```

```{r}
library('class')
#train the model

k1 = knn(train = train01,test = test01,cl = train01$HeartDisease,k = 14 )
k2 = knn(train = train02,test = test02,cl = train02$HeartDisease,k = 14 )
k3 = knn(train = train03,test = test03,cl = train03$HeartDisease,k = 14 )
k4 = knn(train = train04,test = test04,cl = train04$HeartDisease,k = 14 )
k5 = knn(train = train05,test = test05,cl = train05$HeartDisease,k = 14 )

#get accuracy
acc1 = sum(test01$outcome==k1)/nrow(test01)
acc2 = sum(test02$outcome==k2)/nrow(test02)
acc3 = sum(test03$outcome==k3)/nrow(test03)
acc4 = sum(test04$outcome==k4)/nrow(test04)
acc5 = sum(test05$outcome==k5)/nrow(test05)

print(c(acc1,acc2,acc3,acc4,acc5))
avg = (acc1+acc2+acc3+acc4)/5
print(c("Average accuracy: ", avg))

```

#Random forest variable selection
```{r}
library(Boruta)
boruta <- Boruta(HeartDisease ~ ., data = df, doTrace = 2, maxRuns = 500)
plot(boruta, las = 2, cex.axis = 0.7)
```
```{r}
plotImpHistory(boruta)
```

#train a random forest model and evaluate it
```{r}
library(randomForest)
library(caret)
rf = randomForest(HeartDisease ~ ., data = train, importance = TRUE, proximity = TRUE)
plot(rf)
print(rf)
```

#Generate best mtry value for model
```{r}
tuner = tuneRF(train[,-ncol(train)], train$HeartDisease,
               stepFactor = .8,
               plot=T,
               ntreeTry = 500,
               improve = 0.01)

```
```{r}
optRf = randomForest(HeartDisease~., data = train, mtry = 2, ntree = 500)
varImpPlot(optRf,
           sort = T,
           n.var=11,
           main = 'Top Variables')
p = predict(optRf, test)
confusionMatrix(p, test$HeartDisease)

```
```{r}
library(naivebayes)
bayes = naive_bayes(HeartDisease ~ ., data = train)
p = predict(bayes, test)
confusionMatrix(p, test$HeartDisease)
```
```{r}
library('MASS')
lda = lda(HeartDisease~.,train)
lda
lda_p_test = predict(lda,test)
confusionTab = table(predicted = lda_p_test$class, Actual = test$HeartDisease)
confusionTab
acc = (96+133)/276
print(acc)
```

